<!DOCTYPE html>
<html>

    <head>

        <meta charset="utf-8">
        <base href=".">
        <title>Joel Salzman</title>

        <link rel="stylesheet" type="text/css" href="theme.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
        <script type="module" src="./index.js"></script>

    </head>

    <body>

        <!-- Sticky -->

        <svg id="diagram" width="100%" height="100%">
            <!-- drawn from index.js -->
        </svg>

        <div class="core">

            <div class="hud" id="button-div">
                <a class="button" id="Home"      href="#"></a>
                <a class="button" id="Email"     href="mailto:joel.salzman@columbia.edu"></a>
                <a class="button" id="LinkedIn"  href="https://www.linkedin.com/in/joel-salzman"></a>
                <a class="button" id="GitHub"    href="http://github.com/joelsalzman"></a>
            </div>

        </div>

         <!-- Initial page -->
        <div class="content" id="top">
            <h1>Joel<br>Salzman</h1>
            <h3>M.S. student at Columbia studying Computer Vision & Graphics</h3>
            <img id="prof-pic" src="./pics/prof-pic.JPG">
        </div>

        <!-- VHard -->
        <div class="content" id="vhard-content">

            <div class="stuff">
                <a href="https://www.cs.columbia.edu/">
                    <img class="affiliation" src="./pics/Columbia_logo.png">
                </a>
                <h2><a href="https://github.com/ColumbiaCGUI/VHard">VHard</a></h2>
            </div>

            <div class="stuff">
                <img class="thumbnail" src="./pics/vhard.png">
                <div class="text-box">
                    <p>
                        An XR rock climbing app for kinesthetic rehearsal. 
                        If you climb, chances are you've stood at the base of a hard route and mimed the moves.
                        But what if you could actually see the holds in front of you without climbing up to them?
                        We scanned a <a href="https://moonclimbing.com/">MoonBoard</a> and put it in AR/VR with a 
                            custom shader that lights up where your fingers and palms touch.
                        So, you can practice your exact hand and body positions on the ground with metric accuracy 
                            and live feedback.
                        <br><br>
                        VHard has been accepted as a demo in 
                            <a href="https://ieeeismar.org/">IEEE ISMAR 2024</a>.
                    </p>
                </div>
            </div>

        </div>

        <!-- PolXR -->
        <div class="content" id="viser-content">

            <div class="stuff">
                <a href="https://www.cs.columbia.edu/">
                    <img class="affiliation" src="./pics/Columbia_logo.png">
                </a>
                <h2><a href="https://pgg.ldeo.columbia.edu/projects/VISER">VISER</a></h2>
            </div>

            <div class="stuff">
                <img class="thumbnail" src="./pics/polxr-screenshot.png">
                <div class="text-box">
                    <p>
                        An XR glaciology app. 
                        We visualize radar data in an immersive 3D environment and develop custom UX tools for scientists.
                        <br><br>
                        Using a Quest or Hololens VR/AR headset, users can manipulate radargrams and other 
                            scientific data to study glaciological processes in Antarctica and Greenland.
                        I created the pipeline that ingests radar plots and generates 3D meshes that visualize 
                            the actual locations from where the signals were gathered. 
                        We were the first to model the entire flight trajectory in 3D.
                        <br><br>
                        Since joining the team, I have been named on three publications (see the project site for details).
                    </p>
                </div>
            </div>

        </div>

        <!-- Neurochory -->
        <div class="content" id="neurochory-content">

            <div class="stuff">
                <a href="https://www.cs.columbia.edu/">
                    <img class="affiliation" src="./pics/Columbia_logo.png">
                </a>
                <h2><a href="https://github.com/joelsalzman/neurochory-s24">Neurochoric Radiance Fields</a></h2>
            </div>

            <div class="stuff">
                <img class="thumbnail" src="./pics/hotdog.png">
                <div class="text-box">
                    <p>
                        A combination of Gaussian Splatting and Zip-NeRF.
                        <br><br>
                        Begun as a project for 
                            <a href="https://www.engineering.columbia.edu/faculty/peter-belhumeur">Peter Belhumeur's</a> 
                            <i>Advanced Topics in Deep Learning</i> class,
                            I am attempting to improve the state of the art technique for novel view synthesis
                            by using a neural network to learn a point sampling probability field, 
                            sampling primitives from this field,
                            and then splatting the primitives to render images.
                        <br><br>
                        It kind of works. At minimum, I learned a ton about radiance fields by doing this.
                        The project is fully compatible with <a href="https://github.com/nerfstudio-project/">Nerfstudio</a>.
                    </p>
                </div>
            </div>

        </div>

        <!-- Refleconstruction -->
        <div class="content" id="refleconstruction-content">

            <div class="stuff">
                <a href="https://www.cs.columbia.edu/">
                    <img class="affiliation" src="./pics/Columbia_logo.png">
                </a>
                <h2><a href="https://github.com/joelsalzman/refleconstruction">Refleconstruction</a></h2>
            </div>

            <div class="stuff">
                <img class="thumbnail" src="./pics/refleconstruction.png">
                <div class="text-box">
                    <p>
                        3D reconstruction of objects that are partially seen through reflections.
                        <br><br>
                        Done as a project for 
                            <a href="https://www.cs.columbia.edu/~nayar/">Shree Nayar's</a> class 
                            <i>Computational Imaging</i>, 
                            we wrote a pipeline for an Intel RealSense 455 camera that creates 3D models. 
                        What makes this interesting is that part of each object is seen directly by the camera and 
                            part is only visible through a mirror.
                        So, the object can be reconstructed better if the points seen through the mirror are properly  
                            registered with the directly-seen points.
                        We wrote a self-supervised algorithm that segments and merges these point clouds.
                    </p>
                </div>
            </div>

        </div>

        <!-- LocalAIze -->
        <div class="content" id="localaize-content">

            <div class="stuff">
                <a href="https://www.cs.columbia.edu/">
                    <img class="affiliation" src="./pics/Columbia_logo.png">
                </a>
                <h2><a href="https://github.com/cgauchey/deeplearningfinalproj">LocalAIze</a></h2>
            </div>

            <div class="stuff">
                <img class="thumbnail" src="https://github.com/cgauchey/deeplearningfinalproj/blob/main/data/processedImages/frame_2139_71277.png?raw=true">
                <div class="text-box">
                    <p>
                        Camera pose estimation for an indoor video using a deep neural network.
                        This was a group project for 
                            <a href="https://www.engineering.columbia.edu/faculty/peter-belhumeur">Peter Belhumeur's</a> 
                            <i>Deep Learning for Computer Vision</i> class.
                        Our goal was to figure out where in our classroom a random image was taken from, 
                            given simple conditions (same lighting, no movement, etc).
                        We took a supervised deep learning approach but used COLMAP to estimate the ground truth poses.
                    </p>
                </div>
            </div>

        </div>

        <!-- Apex -->
        <div class="content normal" id="apex-content">

            <div class="stuff" id="content-header">
                <a href="https://www.apexcleanenergy.com/">
                    <img class="affiliation" src="./pics/Apex_logo.png">
                </a>
                <h2>GIS Developer</h2>
            </div>

            <div class="stuff">
                <img class="thumbnail" src="./pics/apex-sitevisit.png">
                <div class="text-box">
                    <p>
                        For over two years, my job was to figure out where to build utility-scale
                            renewable (primarily wind and solar) projects for 
                            <a href="https://www.apexcleanenergy.com/">Apex Clean Energy</a>.
                        Most of my work consisted of data engineering and automated geospatial analysis.
                        My deliverables remain proprietary but I will happily explain what I did and what I
                            learned if asked.
                    </p>
                </div>
            </div>

        </div>

        <!-- GDVP -->
        <div class="content normal" id="gdvp-content">

            <div class="stuff">
                <a href="https://www.geog.ucsb.edu/">
                    <img class="affiliation" src="./pics/UCSB_logo.png">
                </a>
                <h2>
                    <a href="gdvp">Voting Power</a>
                </h2>
            </div>

            <div class="stuff">
                <img class="thumbnail" src="./pics/176c-screenshot.png">
                <div class="text-box">
                    <p>
                        Where do votes matter most? 
                        A project for my last GIS class in college under 
                        <a href="https://www.geog.ucsb.edu/people/faculty/krzysztof-janowicz">Krzysztof Janowicz</a> 
                        that ended up as an interactive web map.
                        See the project page for (many) details.
                    <br><br>
                        Working on this project is a big part of why I decided to go back to school for
                            Computer Science.
                    </p>
                </div>
            </div>

        </div>

        <!-- Kelp -->
        <div class="content normal" id="kelp-content">

            <div class="stuff">
                <a href="https://www.geog.ucsb.edu/">
                    <img class="affiliation" src="./pics/UCSB_logo.png">
                </a>
                <h2>
                    <a href="./pics/Regional_Federal.png">Aquaculture</a>
                </h2>
            </div>

            <div class="stuff">
                <img class="thumbnail" src="./pics/kelp-screenshot.png">
                <div class="text-box">
                    <p>
                        <a href="http://www.primaryocean.com">Primary Ocean Producers</a> is a 
                            startup aiming to cultivate <i>Macrocystis pyrifera</i> in the deep 
                            ocean, in partnership with Catalina Sea Ranch.
                        We were funded by a grant from 
                            <a href="https://arpa-e.energy.gov/technologies/programs/mariner">ARPA-E</a> 
                            to grow giant kelp en masse in order to produce carbon-neutral biofuel.
                    <br><br>
                        My role was to site the pilot facilities off the coast of California.
                        Along with two aquatic biologists, I developed a hierarchical suitability 
                            model for giant kelp cultivation.
                        Among other factors, we looked at chemical availability (for nutrients), 
                            geophysical phenomena (so the kelp would be safe), and legal 
                            restrictions (so we could build the facility).
                    </p>
                </div>
            </div>

        </div>
        
    </body>

</html>